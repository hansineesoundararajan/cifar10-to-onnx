{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "id": "Rhb9zJZHwIzU",
        "outputId": "ba5ff853-1fda-4bc0-ce6d-3ebe3d6bdee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.25.6)\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (1.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tf2onnx) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tf2onnx) (1.17.0)\n",
            "Collecting protobuf>=3.20.2 (from onnx)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime_gpu-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (280.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.8/280.8 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf2onnx-1.16.1-py3-none-any.whl (455 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.8/455.8 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, humanfriendly, onnx, coloredlogs, tf2onnx, onnxruntime-gpu\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnxruntime-gpu-1.21.0 protobuf-3.20.3 tf2onnx-1.16.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "d9774a549fb14dbebcc438a17145c2f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models  # Import Keras modules\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "!pip install onnx onnxruntime-gpu tf2onnx\n",
        "\n",
        "# Import ONNX-related libraries\n",
        "import onnx\n",
        "import onnxruntime\n",
        "import tf2onnx\n",
        "\n",
        "# Import evaluation metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
        "\n",
        "# Load CIFAR-10 dataset (Images are 32x32 RGB images, 10 classes)\n",
        "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to range [0,1] for better training stability\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "# Data augmentation: Helps improve model generalization\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),    # Randomly flip images horizontally\n",
        "    layers.RandomRotation(0.1),         # Rotate images by a small angle\n",
        "    layers.RandomZoom(0.1),             # Apply a small zoom\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CNN model for image classification\n",
        "cnn = models.Sequential([\n",
        "    layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),  # Pooling reduces spatial dimensions\n",
        "\n",
        "    layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),                # Flatten into 1D array for Dense layers\n",
        "    layers.Dense(128, activation='relu'),  # Fully connected layer\n",
        "    layers.Dense(10, activation='softmax') # Output layer (10 classes, softmax for classification)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "cnn.compile(optimizer='adam',          # Adam optimizer (adaptive learning rate)\n",
        "            loss='sparse_categorical_crossentropy',  # Suitable for integer labels\n",
        "            metrics=['accuracy'])       # Track accuracy\n",
        "\n",
        "# Train the model for 10 epochs\n",
        "cnn.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# Evaluate model performance on test data\n",
        "cnn.evaluate(X_test, y_test)\n",
        "\n",
        "# Save trained model in TensorFlow SavedModel format\n",
        "tf.saved_model.save(cnn, \"cnn_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT7-lwJrxq7b",
        "outputId": "f2a378d1-07a2-4bfd-9368-0a459009f093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 103ms/step - accuracy: 0.3535 - loss: 1.7524\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 94ms/step - accuracy: 0.5991 - loss: 1.1370\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 94ms/step - accuracy: 0.6659 - loss: 0.9549\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 95ms/step - accuracy: 0.7103 - loss: 0.8221\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 93ms/step - accuracy: 0.7407 - loss: 0.7414\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 94ms/step - accuracy: 0.7649 - loss: 0.6713\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 105ms/step - accuracy: 0.7892 - loss: 0.5985\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 95ms/step - accuracy: 0.8109 - loss: 0.5396\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 97ms/step - accuracy: 0.8278 - loss: 0.4940\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 95ms/step - accuracy: 0.8379 - loss: 0.4589\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.7401 - loss: 0.8258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to ONNX (Colab Safe)\n",
        "!python -m tf2onnx.convert --saved-model cnn_model --output cnn_model.onnx\n",
        "\n",
        "# Load ONNX model\n",
        "onnx_model = onnx.load(\"cnn_model.onnx\")\n",
        "onnx.checker.check_model(onnx_model)\n",
        "\n",
        "# Run inference on CPU using ONNX Runtime\n",
        "ort_session = onnxruntime.InferenceSession(\"cnn_model.onnx\", providers=['CPUExecutionProvider'])\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.numpy() if hasattr(tensor, 'numpy') else tensor\n",
        "\n",
        "# Prepare input for ONNX\n",
        "X_test_onnx = to_numpy(X_test).astype(np.float32)\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: X_test_onnx}\n",
        "\n",
        "# Run inference\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "# Get predictions\n",
        "y_pred = np.argmax(ort_outs[0], axis=1)\n",
        "\n",
        "# Evaluate model\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
        "print('F1 Score:', f1_score(y_test, y_pred, average='weighted'))\n",
        "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
        "print('Recall:', recall_score(y_test, y_pred, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA7kB4FN5iHf",
        "outputId": "5a5cae08-7023-4bf7-ede0-3076420fdb12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741792384.380186    9936 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741792384.389329    9936 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "<frozen runpy>:128: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
            "2025-03-12 15:13:12,715 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
            "2025-03-12 15:13:12,717 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
            "2025-03-12 15:13:13,168 - INFO - Signatures found in model: [serving_default].\n",
            "2025-03-12 15:13:13,169 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
            "2025-03-12 15:13:13,169 - INFO - Output names: ['output_0']\n",
            "I0000 00:00:1741792393.191644    9936 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1741792393.191929    9936 single_machine.cc:361] Starting new session\n",
            "I0000 00:00:1741792393.426366    9936 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "I0000 00:00:1741792393.426557    9936 single_machine.cc:361] Starting new session\n",
            "2025-03-12 15:13:13,498 - INFO - Using tensorflow=2.18.0, onnx=1.17.0, tf2onnx=1.16.1/15c810\n",
            "2025-03-12 15:13:13,498 - INFO - Using opset <onnx, 15>\n",
            "2025-03-12 15:13:13,519 - INFO - Computed 0 values for constant folding\n",
            "2025-03-12 15:13:13,565 - INFO - Optimizing ONNX model\n",
            "2025-03-12 15:13:13,654 - INFO - After optimization: Cast -1 (1->0), Identity -2 (2->0), Transpose -10 (12->2)\n",
            "2025-03-12 15:13:13,662 - INFO - \n",
            "2025-03-12 15:13:13,662 - INFO - Successfully converted TensorFlow model cnn_model to ONNX\n",
            "2025-03-12 15:13:13,662 - INFO - Model inputs: ['inputs']\n",
            "2025-03-12 15:13:13,662 - INFO - Model outputs: ['output_0']\n",
            "2025-03-12 15:13:13,662 - INFO - ONNX model is saved at cnn_model.onnx\n",
            "Accuracy: 0.7326\n",
            "F1 Score: 0.7314618947456722\n",
            "Precision: 0.736053749101422\n",
            "Recall: 0.7326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Run inference multiple times to measure speed\n",
        "start_time = time.time()\n",
        "for _ in range(100):  # Run 100 times for better benchmarking\n",
        "    ort_outs = ort_session.run(None, ort_inputs)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Average inference time: {(end_time - start_time) / 100:.6f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fQC4W487TGw",
        "outputId": "42328068-9b7a-4057-cba2-4e3d8fbb4967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average inference time: 5.710011 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# TensorFlow Model Inference\n",
        "start_tf = time.time()\n",
        "cnn_predictions = cnn.predict(X_test)\n",
        "end_tf = time.time()\n",
        "print(f\"TensorFlow Inference Time: {(end_tf - start_tf) / len(X_test):.6f} sec per sample\")\n",
        "\n",
        "# ONNX Model Inference\n",
        "start_onnx = time.time()\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "end_onnx = time.time()\n",
        "print(f\"ONNX Runtime Inference Time: {(end_onnx - start_onnx) / len(X_test):.6f} sec per sample\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x96WAXSc7nIX",
        "outputId": "5f5512ae-5b55-4fff-f5d1-b4a2ad7e9525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
            "TensorFlow Inference Time: 0.000838 sec per sample\n",
            "ONNX Runtime Inference Time: 0.001213 sec per sample\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert TensorFlow predictions\n",
        "y_pred_tf = np.argmax(cnn_predictions, axis=1)\n",
        "\n",
        "# Convert ONNX predictions\n",
        "y_pred_onnx = np.argmax(ort_outs[0], axis=1)\n",
        "\n",
        "# Compare accuracy\n",
        "print(\"TensorFlow Accuracy:\", accuracy_score(y_test, y_pred_tf))\n",
        "print(\"ONNX Runtime Accuracy:\", accuracy_score(y_test, y_pred_onnx))\n",
        "\n",
        "# Check similarity between TensorFlow and ONNX predictions\n",
        "matching = np.sum(y_pred_tf == y_pred_onnx) / len(y_test) * 100\n",
        "print(f\"Prediction Match: {matching:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssYiJXp17tcM",
        "outputId": "900fd484-7019-4e42-d0c2-27a6ba7fe16b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Accuracy: 0.7326\n",
            "ONNX Runtime Accuracy: 0.7326\n",
            "Prediction Match: 100.00%\n"
          ]
        }
      ]
    }
  ]
}